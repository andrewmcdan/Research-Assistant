# **High Level Vision**

You are building an application that can generate deeply researched guides, manuals, and technical documents by orchestrating:

1. LLM-powered planning and discussion with the user.

2. Automated research via puppeteer-driven web searches and webpage captures.

3. A structured, iterative writing pipeline based on an outline created by the LLM.

4. Persistent storage of research material in Markdown for transparency and auditability.

The LLM becomes a **research planner, researcher, and writer**, but with controlled steps, consistently producing a complete and academically structured document.

---

# **System Architecture Overview**

**Frontend:**

* Could be web or mobile. User interacts with a simple conversational or form-based interface.

**Backend Core (NodeJS):**

* Controls the workflow.

* Handles puppeteer research tasks.

* Maintains document state, logs, and intermediate files.

* Calls GPT-5.1 for planning, research synthesis, outline creation, and writing.

**Internal Storage:**

* Markdown file repository (local disk or cloud storage).

* Metadata about research files (timestamps, URLs, extraction type).

* Outline structure (JSON).

* Final and intermediate document versions.

---

# **Detailed App Flow**

## **Step 1\. Ask the user for the topic**

The app starts very simply:

* Prompt: “What would you like a guide or manual about?”

* User provides: “butchering meat” or “building a solar power system” or “troubleshooting a diesel generator.”

**State captured:**

* `topic: string`

---

## **Step 2\. Ask for depth and breadth**

Your app should ask clarifying questions generated by the LLM, but driven by a template:

### **Two Concepts to Define**

**Breadth:**  
 How wide should the guide be?  
 Examples for butchering:

* All livestock species

* Only cows and pigs

* Only final breakdown cuts

* Only knife techniques

* Including humane killing or not

**Depth:**  
 How detailed?  
 Examples:

* High level overview

* Intermediate detail per species

* Complete expert-level step-by-step

* Include safety, food science, storage methods, butchering room setup, tool maintenance, etc.

### **Process**

1. LLM generates a list of possible breadth/depth levels appropriate for the topic.

2. User chooses or customizes them.

3. The backend stores:

`{`  
  `topic: "Butchering meat",`  
  `depth_level: "Expert, step-by-step",`  
  `breadth: ["cows", "pigs"],`  
  `include_humane_kill: true,`  
  `include_freezing_and_preservation: true`  
`}`

These settings drive the research load and the scope of the outline.

---

## **Step 3\. Automated research (Puppeteer \+ LLM guidance)**

### **Key Design Principles**

* The LLM should not hallucinate knowledge here.

* Its job is to *generate search queries* and *describe what it needs*.

* The backend executes those searches using puppeteer.

### **Research workflow:**

#### **3.1 LLM generates:**

* A set of search queries (Google/Bing)

* A list of domains to avoid (junk SEO, clickbait)

* A list of key subtopics requiring research

#### **3.2 Puppeteer executes searches:**

* Fetch top N search results.

* For each result:

  * Load the page

  * Extract readable text

  * Remove noise (ads, navigation)

  * Save as markdown

Include metadata at top:

 `---`  
`source: URL`  
`search_query: "how to butcher a cow step by step"`  
`timestamp: 2025-11-14`  
`---`

* 

#### **3.3 LLM reviews the collected markdown files:**

* It summarizes each research document.

* It flags low-quality sources.

* It identifies gaps in information.

* If necessary, it triggers additional puppeteer searches.

**Output:**

* A structured research corpus of markdown files, each per page.

* A metadata JSON linking them to outline segments.

---

## **Step 4\. Create a high-level outline**

This is where GPT-5.1 shines.  
 It uses:

* User topic

* Breadth/depth settings

* Summaries of research materials

The outline should follow a hierarchical structure, like:

`[`  
  `{`  
    `"title": "Introduction",`  
    `"children": [`  
      `{ "title": "Purpose of this manual" },`  
      `{ "title": "Safety warnings" }`  
    `]`  
  `},`  
  `{`  
    `"title": "Animal Processing Overview",`  
    `"children": [`  
      `{ "title": "Humane killing", "include_if": "include_humane_kill" },`  
      `{ "title": "Initial cleaning" }`  
    `]`  
  `},`  
  `{`  
    `"title": "Species-specific Guides",`  
    `"children": [`  
      `{`  
        `"title": "Cow butchering",`  
        `"children": [...]`  
      `},`  
      `{`  
        `"title": "Pig butchering",`  
        `"children": [...]`  
      `}`  
    `]`  
  `}`  
`]`

This outline is both machine-readable and human-readable.

---

## **Step 5\. Iterative subsection writing (LLM \+ research corpus)**

This is crucial:  
 You want the LLM to write high-quality sections, each grounded in the research.

### **For each outline section:**

1. Backend provides the LLM with:

   * Section title

   * Relevant research excerpts

   * Source metadata

   * User depth/breadth settings

   * Writing style rules (e.g., plain English, structured sections, no hallucinated facts)

2. LLM writes:

   * The section content

   * Citations referencing the markdown research files

   * Optional images or diagrams (generated or suggested)

3. Backend saves:

   * `/manual/02-cow-butchering/01-overview.md`

   * and also a JSON with internal structure if needed.

4. The process continues recursively through the entire outline tree.

---

# **Additional Features to Plan For**

## **Version Control**

Git integration is valuable. Each research file, outline, and section can be a commit.

## **User Editing and Refinement**

Allow the user to make changes at the outline level or section level before writing proceeds.

## **Regeneration Options**

* Regenerate only a section

* Expand a section to deeper detail

* Condense for a quick reference

## **Generation of Multiple Outputs**

Once all sections exist:

* Combine to a single Markdown

* Convert to PDF (via Pandoc)

* Convert to EPUB

* Create a "field guide" condensed version

## **Authentication and API Keys**

User must provide their OpenAI key unless you centrally manage.

---

# **Data Structures Summary**

**User config:**

`{`  
  `topic,`  
  `depth_level,`  
  `breadth,`  
  `optional_flags: {...}`  
`}`

**Research corpus:**  
 Directory of `.md` files, each with:

* URL

* Query used

* Timestamp

* Extracted content

**Outline:**  
 JSON tree of sections.

**Final document:**  
 Either per-section files or combined markdown.

---
