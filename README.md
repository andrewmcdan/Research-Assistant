# Research Assistant Scaffold

Backend-focused scaffold that turns the **High Level Vision** document into a runnable workflow service. It provides the orchestration surface for planning, automated research, and structured writing while keeping storage transparent via Markdown/JSON artifacts.

## Repository Layout

- `backend/` – TypeScript Node service coordinating the research workflow (Express, OpenAI SDK, Puppeteer, Zod).
- `data/research` – Markdown captures and extracts grouped per artifact ID.
- `data/outlines` – JSON outline trees generated per session.
- `data/documents` – Authored section files, combined manuals, and persisted session snapshots.
- `High Level Vision.md` – Product brief that guided the scaffold.

## Getting Started

```bash
cd backend
cp .env.example .env   # add OPENAI_API_KEY when ready to call GPT
npm install
npm run dev
```

The API listens on `PORT` (defaults to `4000`).

### Frontend Chat Workspace

```bash
cd frontend
cp .env.example .env     # adjust VITE_API_BASE_URL if the backend runs elsewhere
npm install
npm run dev
```

The Vite dev server runs on `5173` and proxies directly to the backend API URL from the env file.

## Core Concepts

1. **Session bootstrapping** – `POST /api/sessions` seeds a workflow session and returns clarifying questions generated by the LLM service (mockable without an API key).
2. **Scope capture** – `POST /api/sessions/:id/scope` locks breadth/depth configuration, stores it, and produces an outline tree saved under `data/outlines`.
3. **Research planning** – `GET /api/sessions/:id/research-plan` requests search query suggestions. `POST /api/sessions/:id/research` ingests an actual URL capture through Puppeteer and saves the HTML + metadata bundle.
4. **Iterative writing** – `POST /api/sessions/:id/sections` composes a section by combining outline context, stored scope, and referenced research metadata before persisting Markdown under `data/documents`.

Each stage is implemented as a dedicated service (planning, research, storage, writing) orchestrated by `SessionWorkflow`.

## Next Steps

- Connect a frontend (web or mobile) to the REST API or swap Express for a command bus if you prefer job workers.
- Wire real OpenAI prompts per workflow method and extend the mock outputs with fixtures for offline development.
- Expand research ingestion to support screenshot capture, PDF exports, and deduplication heuristics.
- Layer authentication/API key management before exposing the API publicly.
- Enhance the new chat interface with streaming responses, research capture playback, and editing controls for outline sections.
